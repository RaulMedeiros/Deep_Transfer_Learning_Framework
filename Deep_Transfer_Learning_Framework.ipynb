{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Transfer_Learning_Framework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RaulMedeiros/Deep_Transfer_Learning_Framework/blob/master/Deep_Transfer_Learning_Framework.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "s9uazIVjkJCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "263a87ea-1006-4e71-8e71-c7ac02d7f9a0"
      },
      "cell_type": "code",
      "source": [
        "# # Remove Older Files.\n",
        "# !ls\n",
        "# !rm -r *\n",
        "# !ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  data\tdata.zip  out\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qv9WnMxGrE_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CONFIG DEEP FEATURE EXTRACTOR**"
      ]
    },
    {
      "metadata": {
        "id": "nNc-Fk88oRVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src_drive_folder_id = '1A5ByNWx7Nr72uOzXMy3bwLHDwShQgqYc'\n",
        "drive_filenames = ['data.zip']\n",
        "out_drive_folder_id = '1Zkx5UfATBDCmQP4A4VDzFYTjjy6LIbq3'\n",
        "\n",
        "#Especifique a topologia a ser utilizada.\n",
        "model_name_list = ['MobileNet',\n",
        "                   'ResNet50',\n",
        "                   'Xception',\n",
        "                   'VGG16',\n",
        "                   'VGG19',\n",
        "                   'InceptionV3',\n",
        "                   'InceptionResNetV2',\n",
        "                   'NASNetMobile',\n",
        "                   'NASNetLarge','DenseNet121','DenseNet169','DenseNet201']  \n",
        "\n",
        "# #Especifique a topologia a ser utilizada.\n",
        "model_name_list = ['DenseNet201']  \n",
        "\n",
        "#Especifique o formato de saida\n",
        "output_fmt = ['txt','npy']    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFu27EfmrRpq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Authenticate and create the PyDrive client**"
      ]
    },
    {
      "metadata": {
        "id": "dvf8DykEPz1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-zVWZ8Zrbdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Donwload and Unzip Data.zip**"
      ]
    },
    {
      "metadata": {
        "id": "MaENTbD1dgoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "cellView": "code",
        "outputId": "7fe4ea70-7253-4f7e-e0a6-290dc2cc03fb"
      },
      "cell_type": "code",
      "source": [
        "#!pip3 install -q pandas\n",
        "import pandas as pd\n",
        "\n",
        "import zipfile\n",
        "\n",
        "def unzip(path_to_zip_file,extract_to='./'):\n",
        "  zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "  zip_ref.extractall(extract_to)\n",
        "  zip_ref.close()\n",
        "  return True\n",
        "\n",
        "def load_and_unzip_file(folder_id,target_filenames):\n",
        "  \"\"\"Download and unzip dataset\"\"\"   \n",
        "\n",
        "  info = pd.DataFrame(drive.ListFile({'q': \"'\"+folder_id +\n",
        "                                   \"' in parents and trashed=false\"}).GetList())  \n",
        "  if (info.empty):\n",
        "    print('Empty Drive Folder!')\n",
        "    return False\n",
        "  \n",
        "  else:\n",
        "    for f_name, drive_id in zip(info['title'].values, info['id'].values):\n",
        "      if (f_name in target_filenames):      \n",
        "        print(drive_id,f_name)\n",
        "        downloaded = drive.CreateFile({'id': drive_id }).GetContentFile(f_name)\n",
        "        unzip(f_name, extract_to='./')\n",
        "        !ls\n",
        "  return True\n",
        "\n",
        "## Load and Unconpress data\n",
        "load_and_unzip_file(src_drive_folder_id,drive_filenames)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1meShW1ucL2OlRqPCYN5eLCEvgmxSlchX data.zip\n",
            "adc.json  data\tdata.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "LoJV1B0Uro1l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sample of files into class/folder 0**"
      ]
    },
    {
      "metadata": {
        "id": "ZMgjfNc0eA2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "outputId": "209126d4-e74a-4af2-db44-2644ab304e90"
      },
      "cell_type": "code",
      "source": [
        "!ls data/0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.jpg  142.jpg  184.jpg  225.jpg  267.jpg  308.jpg  34.jpg   391.jpg\t63.jpg\r\n",
            "101.jpg  143.jpg  185.jpg  226.jpg  268.jpg  309.jpg  350.jpg  392.jpg\t64.jpg\r\n",
            "102.jpg  144.jpg  186.jpg  227.jpg  269.jpg  30.jpg   351.jpg  393.jpg\t65.jpg\r\n",
            "103.jpg  145.jpg  187.jpg  228.jpg  26.jpg   310.jpg  352.jpg  394.jpg\t66.jpg\r\n",
            "104.jpg  146.jpg  188.jpg  229.jpg  270.jpg  311.jpg  353.jpg  395.jpg\t67.jpg\r\n",
            "105.jpg  147.jpg  189.jpg  22.jpg   271.jpg  312.jpg  354.jpg  396.jpg\t68.jpg\r\n",
            "106.jpg  148.jpg  18.jpg   230.jpg  272.jpg  313.jpg  355.jpg  397.jpg\t69.jpg\r\n",
            "107.jpg  149.jpg  190.jpg  231.jpg  273.jpg  314.jpg  356.jpg  398.jpg\t6.jpg\r\n",
            "108.jpg  14.jpg   191.jpg  232.jpg  274.jpg  315.jpg  357.jpg  399.jpg\t70.jpg\r\n",
            "109.jpg  150.jpg  192.jpg  233.jpg  275.jpg  316.jpg  358.jpg  39.jpg\t71.jpg\r\n",
            "10.jpg\t 151.jpg  193.jpg  234.jpg  276.jpg  317.jpg  359.jpg  3.jpg\t72.jpg\r\n",
            "110.jpg  152.jpg  194.jpg  235.jpg  277.jpg  318.jpg  35.jpg   400.jpg\t73.jpg\r\n",
            "111.jpg  153.jpg  195.jpg  236.jpg  278.jpg  319.jpg  360.jpg  401.jpg\t74.jpg\r\n",
            "112.jpg  154.jpg  196.jpg  237.jpg  279.jpg  31.jpg   361.jpg  402.jpg\t75.jpg\r\n",
            "113.jpg  155.jpg  197.jpg  238.jpg  27.jpg   320.jpg  362.jpg  403.jpg\t76.jpg\r\n",
            "114.jpg  156.jpg  198.jpg  239.jpg  280.jpg  321.jpg  363.jpg  404.jpg\t77.jpg\r\n",
            "115.jpg  157.jpg  199.jpg  23.jpg   281.jpg  322.jpg  364.jpg  405.jpg\t78.jpg\r\n",
            "116.jpg  158.jpg  19.jpg   240.jpg  282.jpg  323.jpg  365.jpg  406.jpg\t79.jpg\r\n",
            "117.jpg  159.jpg  1.jpg    241.jpg  283.jpg  324.jpg  366.jpg  407.jpg\t7.jpg\r\n",
            "118.jpg  15.jpg   200.jpg  242.jpg  284.jpg  325.jpg  367.jpg  408.jpg\t80.jpg\r\n",
            "119.jpg  160.jpg  201.jpg  243.jpg  285.jpg  326.jpg  368.jpg  409.jpg\t81.jpg\r\n",
            "11.jpg\t 161.jpg  202.jpg  244.jpg  286.jpg  327.jpg  369.jpg  40.jpg\t82.jpg\r\n",
            "120.jpg  162.jpg  203.jpg  245.jpg  287.jpg  328.jpg  36.jpg   41.jpg\t83.jpg\r\n",
            "121.jpg  163.jpg  204.jpg  246.jpg  288.jpg  329.jpg  370.jpg  42.jpg\t84.jpg\r\n",
            "122.jpg  164.jpg  205.jpg  247.jpg  289.jpg  32.jpg   371.jpg  43.jpg\t85.jpg\r\n",
            "123.jpg  165.jpg  206.jpg  248.jpg  28.jpg   330.jpg  372.jpg  44.jpg\t86.jpg\r\n",
            "124.jpg  166.jpg  207.jpg  249.jpg  290.jpg  331.jpg  373.jpg  45.jpg\t87.jpg\r\n",
            "125.jpg  167.jpg  208.jpg  24.jpg   291.jpg  332.jpg  374.jpg  46.jpg\t88.jpg\r\n",
            "126.jpg  168.jpg  209.jpg  250.jpg  292.jpg  333.jpg  375.jpg  47.jpg\t89.jpg\r\n",
            "127.jpg  169.jpg  20.jpg   251.jpg  293.jpg  334.jpg  376.jpg  48.jpg\t8.jpg\r\n",
            "128.jpg  16.jpg   210.jpg  252.jpg  294.jpg  335.jpg  377.jpg  49.jpg\t90.jpg\r\n",
            "129.jpg  170.jpg  211.jpg  253.jpg  295.jpg  336.jpg  378.jpg  4.jpg\t91.jpg\r\n",
            "12.jpg\t 171.jpg  212.jpg  254.jpg  296.jpg  337.jpg  379.jpg  50.jpg\t92.jpg\r\n",
            "130.jpg  172.jpg  213.jpg  255.jpg  297.jpg  338.jpg  37.jpg   51.jpg\t93.jpg\r\n",
            "131.jpg  173.jpg  214.jpg  256.jpg  298.jpg  339.jpg  380.jpg  52.jpg\t94.jpg\r\n",
            "132.jpg  174.jpg  215.jpg  257.jpg  299.jpg  33.jpg   381.jpg  53.jpg\t95.jpg\r\n",
            "133.jpg  175.jpg  216.jpg  258.jpg  29.jpg   340.jpg  382.jpg  54.jpg\t96.jpg\r\n",
            "134.jpg  176.jpg  217.jpg  259.jpg  2.jpg    341.jpg  383.jpg  55.jpg\t97.jpg\r\n",
            "135.jpg  177.jpg  218.jpg  25.jpg   300.jpg  342.jpg  384.jpg  56.jpg\t98.jpg\r\n",
            "136.jpg  178.jpg  219.jpg  260.jpg  301.jpg  343.jpg  385.jpg  57.jpg\t99.jpg\r\n",
            "137.jpg  179.jpg  21.jpg   261.jpg  302.jpg  344.jpg  386.jpg  58.jpg\t9.jpg\r\n",
            "138.jpg  17.jpg   220.jpg  262.jpg  303.jpg  345.jpg  387.jpg  59.jpg\r\n",
            "139.jpg  180.jpg  221.jpg  263.jpg  304.jpg  346.jpg  388.jpg  5.jpg\r\n",
            "13.jpg\t 181.jpg  222.jpg  264.jpg  305.jpg  347.jpg  389.jpg  60.jpg\r\n",
            "140.jpg  182.jpg  223.jpg  265.jpg  306.jpg  348.jpg  38.jpg   61.jpg\r\n",
            "141.jpg  183.jpg  224.jpg  266.jpg  307.jpg  349.jpg  390.jpg  62.jpg\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P28gIt6kr8GH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Install Libraries **"
      ]
    },
    {
      "metadata": {
        "id": "HTqjyobxaAIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "# https://opencv.org/\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import keras\n",
        "from keras import backend as tf\n",
        "from scipy import misc\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input as ppi_inceptionresnet_v2\n",
        "from keras.applications.vgg16 import preprocess_input as ppi_vgg16\n",
        "from keras.applications.vgg19 import preprocess_input as ppi_vgg19\n",
        "from keras.applications.xception import preprocess_input as ppi_xception\n",
        "from keras.applications.resnet50 import preprocess_input as ppi_resnet50\n",
        "from keras.applications.inception_v3 import preprocess_input as ppi_inception_v3\n",
        "from keras.applications.mobilenet import preprocess_input as ppi_mobilenet\n",
        "from keras.applications.nasnet import preprocess_input as ppi_nasnet\n",
        "from keras.applications.densenet import preprocess_input as ppi_densenet\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input\n",
        "\n",
        "np.set_printoptions(threshold=np.nan)\n",
        "keras.backend.backend()\n",
        "\n",
        "import time\n",
        "current_milli_time = lambda: int(round(time.time() * 1000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xB3o4BGlPvNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(model_name,pooltype='max'):\n",
        "    if ('VGG16' is model_name):\n",
        "        model = VGG16(weights='imagenet',pooling=pooltype, include_top=False)    \n",
        "    if ('VGG19' is model_name):\n",
        "        model = VGG19(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('MobileNet' is model_name):\n",
        "        input_tensor = Input(shape=(224,224,3))\n",
        "        model = MobileNet(weights='imagenet',pooling=pooltype,input_shape=(224,224,3),include_top=False)  \n",
        "    if ('ResNet50' is model_name):\n",
        "        model = ResNet50(weights='imagenet',pooling=pooltype, include_top=False)       \n",
        "    if ('InceptionV3' is model_name):\n",
        "        model = InceptionV3(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('Xception' is model_name):\n",
        "        model = Xception(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('InceptionResNetV2' is model_name):\n",
        "        model = InceptionResNetV2(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('NASNetMobile' is model_name):\n",
        "        model = NASNetMobile(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('NASNetLarge' is model_name):\n",
        "        model = NASNetLarge(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('DenseNet121' is model_name):\n",
        "        model = DenseNet121(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('DenseNet169' is model_name):\n",
        "        model = DenseNet169(weights='imagenet',pooling=pooltype, include_top=False)\n",
        "    if ('DenseNet201' is model_name):\n",
        "        model = DenseNet201(weights='imagenet',pooling=pooltype, include_top=False)    \n",
        "                \n",
        "    if (model_name in ['InceptionV3','Xception','InceptionResNetV2']):\n",
        "        targetSize = 299  \n",
        "    elif(model_name in ['NASNetLarge']):\n",
        "        targetSize = 331\n",
        "    else:    \n",
        "        targetSize = 224   \n",
        "    \n",
        "    return model,targetSize\n",
        "  \n",
        "def extractDeepFeatures(file_id,model,model_name,target_size,log=False):\n",
        "    \n",
        "    x = load_img(file_id,target_size)\n",
        "    x = image.img_to_array(x)    \n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    if (model_name is 'VGG16'):\n",
        "        x = ppi_vgg16(x)        \n",
        "    if (model_name is 'VGG19'):\n",
        "        x = ppi_vgg19(x)\n",
        "    if (model_name is 'ResNet50'):\n",
        "        x = ppi_resnet50(x)\n",
        "    if (model_name is 'MobileNet'):\n",
        "        x = ppi_mobilenet(x)\n",
        "    if (model_name is 'Xception'):\n",
        "        x = ppi_xception(x) \n",
        "    if (model_name is 'InceptionV3'):\n",
        "        x = ppi_inception_v3(x)\n",
        "    if (model_name is 'InceptionResNetV2'):\n",
        "        x = ppi_inceptionresnet_v2(x)\n",
        "    if (model_name is 'NASNetMobile'):\n",
        "        x = ppi_nasnet(x)\n",
        "    if (model_name is 'NASNetLarge'):\n",
        "        x = ppi_nasnet(x)\n",
        "    if (model_name is 'DenseNet121'):\n",
        "        x = ppi_densenet(x)\n",
        "    if (model_name is 'DenseNet169'):\n",
        "        x = ppi_densenet(x)\n",
        "    if (model_name is 'DenseNet201'):\n",
        "        x = ppi_densenet(x)\n",
        "\n",
        "    timeStart = current_milli_time()\n",
        "    features = model.predict(x).reshape(-1)\n",
        "    process_time = current_milli_time()-timeStart    \n",
        "    if(log): print('Load process: Complete',process_time)\n",
        "\n",
        "    return features,process_time\n",
        "\n",
        "def load_img(filepath,target_size):\n",
        "    \"\"\"Load dataset\"\"\"\n",
        "    #LOAD image to be deep extracted         \n",
        "    if (filepath.endswith('jpg') or filepath.endswith('JPG') ):\n",
        "        img = cv2.imread((filepath))\n",
        "    elif (filepath.endswith('txt')):\n",
        "        img = np.loadtxt(filepath).copy()\n",
        "    elif (filepath.endswith('npy')):\n",
        "        img = np.load(filepath).copy()\n",
        "    elif (filepath.endswith('png') or filepath.endswith('PNG')):\n",
        "        img = misc.imread(filepath).copy()\n",
        "    img = cv2.resize(img, (target_size,target_size), interpolation = cv2.INTER_NEAREST)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9XDaXkysA5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Iterate through each model and each image to extract deep features **"
      ]
    },
    {
      "metadata": {
        "id": "TFPytxpSslxW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deep_extractor(model_name,numOfClasses,out_folder_id,output_fmt=['npy'],\n",
        "              srcPath='./data',outPath='./out'):\n",
        "  print(model_name)\n",
        "  cont = 0\n",
        "\n",
        "  # For each class    \n",
        "  model,targetSize = build_model(model_name)\n",
        "  data = []\n",
        "  process_time_list= []\n",
        "\n",
        "  # Start chronometer\n",
        "  timeStart = current_milli_time()\n",
        "\n",
        "  for fileIdx in range(numOfClasses):\n",
        "    folderPath = srcPath+'/'+str(fileIdx)\n",
        "\n",
        "    # For each sample\n",
        "    for subdir, dirs, files in os.walk(folderPath):\n",
        "      for idx,name in enumerate(files):\n",
        "        filePath = subdir + os.sep + name\n",
        "        cont=cont+1\n",
        "\n",
        "        clear_output()             \n",
        "        print(cont,filePath,model_name) \n",
        "\n",
        "        features,process_time = extractDeepFeatures(filePath,model,model_name,targetSize)\n",
        "        process_time_list.append(process_time)\n",
        "        \n",
        "        features = np.hstack((features,fileIdx))\n",
        "        data.append(features)\n",
        "\n",
        "  # Compute extraction time      \n",
        "  process_time = current_milli_time()-timeStart    \n",
        "    \n",
        "  # Creates a folder if don't exist\n",
        "  os.makedirs(outPath+'/', exist_ok=True) \n",
        "  # Saves a txt file w/ deep features\n",
        "  if('txt' in output_fmt):\n",
        "    np.savetxt(outPath+'/'+model_name+'.txt',data,fmt=\"%.8f\")\n",
        "    #Upload txt file to folder (by id)\n",
        "    file = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\",\n",
        "                                          \"id\": out_folder_id}]})\n",
        "    file.SetContentFile(outPath+'/'+model_name+'.txt')\n",
        "    file.Upload()\n",
        "\n",
        "  #Saves a npy file w/ deep features\n",
        "  if('npy' in output_fmt):\n",
        "    np.save(outPath+'/'+model_name+'.npy',data)      \n",
        "    #Upload npy file to folder (by id)\n",
        "    file = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\",\n",
        "                                          \"id\": out_folder_id}]})\n",
        "    file.SetContentFile(outPath+'/'+model_name+'.npy')\n",
        "    file.Upload() \n",
        "\n",
        "  #Save process time into a file\n",
        "  np.savetxt(outPath+'/'+model_name+'_time.txt',process_time_list,fmt=\"%d\")\n",
        "  #Upload txt file to folder (by id)\n",
        "  file = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\",\n",
        "                                        \"id\": out_folder_id}]})\n",
        "  file.SetContentFile(outPath+'/'+model_name+'_time.txt')\n",
        "  file.Upload()\n",
        "  return process_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8FyqKlWytM2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "46c17a64-4f2f-4621-ef6c-73d60cdca01d"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "## Especifique o caminho da pasta onde estão as imagens a serem processadas.\n",
        "srcPath = './data'\n",
        "\n",
        "## Especifique o caminho da pasta onde serão armazenadas as caracteristicas extridas.\n",
        "outPath = './out'                         \n",
        "\n",
        "#Encontra o numero de classes do problema.\n",
        "numOfClasses = len(glob.glob('./'+srcPath+'/*'))\n",
        "\n",
        "# For each deep model    \n",
        "for model_name in model_name_list:\n",
        "  process_time = deep_extractor(model_name,numOfClasses,out_drive_folder_id,output_fmt,srcPath,outPath)\n",
        "  print('Load process: Complete',process_time)\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2070 ./data/3/080.jpg DenseNet201\n",
            "CPU times: user 4min 53s, sys: 43.7 s, total: 5min 36s\n",
            "Wall time: 5min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DPPdo05tXE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "460b982b-64b5-4ad8-9684-664b7c36be3a"
      },
      "cell_type": "code",
      "source": [
        "print('Done')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p-sCQnqFW1Op",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Qual o tempo de estação médio de cada um dos modelos?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8xQL757pW9i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPv05n7CXAHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}