{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Framework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RaulMedeiros/Deep_Transfer_Learning_Framework/blob/master/Classification_Framework.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lnDS4eoYEMi7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src_folder_id = '1dQHvtUYX_HFXCH6lxSaYfN36_Vztncpv'\n",
        "out_folder_id = '1JqEVlTzcO6m2Fwvd-yyudntbEuCtVENY'\n",
        "\n",
        "#Especifique as topologias a serem utilizadas.\n",
        "model_name_list = ['MobileNet','ResNet50','Xception','VGG16','VGG19',\n",
        "                    'InceptionV3','InceptionResNetV2','NASNetMobile','NASNetLarge',\n",
        "                    'DenseNet121','DenseNet169','DenseNet201']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "03oLcBc7DznO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZflMI3UFpt1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1ebb4b75-58b5-41f0-9edd-6ee4eac0f77b"
      },
      "cell_type": "code",
      "source": [
        "!rm -r data\n",
        "!pip3 install -q pandas\n",
        "!mkdir data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def load_dataset(folder_id):\n",
        "  \"\"\"Download all files into a folder\"\"\"   \n",
        "  info = pd.DataFrame(drive.ListFile({'q': \"title contains '.npy' and '\" +folder_id +\"' in parents and trashed=false\" }).GetList())    \n",
        " \n",
        "  for idx, title in zip(info['id'].values,info['title'].values):\n",
        "    downloaded = drive.CreateFile({'id': idx })\n",
        "    downloaded.GetContentFile('./data/'+title[5:])  ## !!!!!!!!!!!!!!!!!!!./out/\n",
        "   \n",
        "  !ls data\n",
        "  return True\n",
        "\n",
        "#Load and Unconpress data\n",
        "load_dataset(src_folder_id)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseNet121.npy  InceptionResNetV2.npy\tNASNetLarge.npy   VGG16.npy\r\n",
            "DenseNet169.npy  InceptionV3.npy\tNASNetMobile.npy  VGG19.npy\r\n",
            "DenseNet201.npy  MobileNet.npy\t\tResNet50.npy\t  Xception.npy\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "G9MxjwuzCGBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "import itertools\n",
        "from keras.utils import np_utils\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "#         print(\"Normalized confusion matrix\")\n",
        "#     else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "#     print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def calc_scores(clf, X, y,clf_name,class_names, cv, plot_cnf_matrix, figsize, normalize):\n",
        "    \n",
        "#     ## Compute Evaluation Metrics\n",
        "#     scores = cross_val_score(clf, X, y, cv=cv)\n",
        "#     print(clf_name,np.mean(scores))\n",
        "        \n",
        "    scoring = ['accuracy', 'precision','recall','f1','roc_auc']\n",
        "    scores = cross_validate(clf, X, y, cv=cv ,scoring=scoring)\n",
        "    print('\\n',clf_name,'\\nAccuracy',np.array(np.mean(scores['test_accuracy'])),\n",
        "                        '\\nPrecision',np.array(np.mean(scores['test_precision'])),                     \n",
        "                        '\\nRecall',np.array(np.mean(scores['test_recall'])),\n",
        "                        '\\nF1',np.array(np.mean(scores['test_f1'])),\n",
        "                        '\\nROC_AUC',np.array(np.mean(scores['test_roc_auc'])))\n",
        "    \n",
        "    means = [np.array(np.mean(scores['test_accuracy'])),\n",
        "#              np.array(np.mean(scores['test_precision'])),\n",
        "#              np.array(np.mean(scores['test_recall'])),\n",
        "#              np.array(np.mean(scores['test_f1'])),\n",
        "             np.array(np.mean(scores['test_roc_auc']))]\n",
        "    \n",
        "    print('means:',np.mean(np.array(means)))\n",
        "    \n",
        "    \n",
        "    ## Compute Confusion matrix\n",
        "    y_pred = cross_val_predict(clf,X,y,cv=cv)\n",
        "    cnf_matrix = confusion_matrix(y,y_pred)\n",
        "    \n",
        "    # Plot Confusion matrix\n",
        "    if (plot_cnf_matrix):\n",
        "        plt.figure(figsize=figsize)\n",
        "        if (normalize):\n",
        "            title = ' Normalized confusion matrix'\n",
        "        else:\n",
        "            title = ' non-Normalized confusion matrix'\n",
        "        class_names = ['0']\n",
        "        plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=normalize,title=clf_name+title)\n",
        "        plt.show()\n",
        "    \n",
        "def load_Ds(folder_Path):\n",
        "    ds = np.load(folder_Path)\n",
        "    X = np.array(ds[:,:-1])\n",
        "    y = np.array(list(map(int,ds[:,-1])))\n",
        "    return X,y\n",
        "\n",
        "#Normalized Data\n",
        "def normalizeX(X):        \n",
        "    X = np.array(X - np.mean(X))\n",
        "    X = np.array(((X-np.min(X))/(np.max(X)-np.min(X))))     \n",
        "    return X\n",
        "\n",
        "def shuffle(x_data, y_data):\n",
        "    c = list(zip(x_data, y_data))\n",
        "    random.shuffle(c)\n",
        "    X,y = zip(*c)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X,y\n",
        "\n",
        "def simplifly(X,y):   \n",
        "    idx_list = [idx for idx, k in enumerate(y) if k!=2]    \n",
        "    X = np.array(X[idx_list])\n",
        "    y = np.array(y[idx_list])\n",
        "    \n",
        "    # Binary problem\n",
        "    y = np.array([0 if k<2 else k for k in y])\n",
        "#     y = np.array([1 if k==2 else k for k in y])        \n",
        "    y = np.array([1 if k>2 else k for k in y])\n",
        "    \n",
        "    # Multiclas problem\n",
        "#     y = np.array([2 if k==3 else k for k in y])\n",
        "#     y = np.array([3 if k==4 else k for k in y])\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBNKxG3wo0zB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.metrics import f1_score\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import make_scorer\n",
        "\n",
        "# scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "#            'f1_score': make_scorer(f1_score),\n",
        "#            'confusion_matrix': make_scorer(confusion_matrix)}\n",
        "\n",
        "#  scores = cross_validate(clf, X, y, cv=cv ,scoring=scoring)    \n",
        "#  print('\\n',clf_name,'\\t',np.round(np.array(np.mean(scores['test_accuracy'])), 4))\n",
        "# #        '\\t',np.round(np.array(np.mean(scores['test_f1_score'])), 4),\n",
        "# #        '\\t',np.round(np.array(np.mean(scores['test_confusion_matrix'])), 4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hUuVcx-DpNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "96116353-8190-4e7b-e287-afac605bce32"
      },
      "cell_type": "code",
      "source": [
        "% time\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import *\n",
        "\n",
        "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
        "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
        "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
        "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
        "\n",
        "\n",
        "class_weight = {0: 1 ,1: 1}\n",
        "\n",
        "#Especifique se a matriz de confusão deve ser plotada\n",
        "plot_cnf_matrix= False\n",
        "#Especifique se a matriz de confusão plotada deve ser normalizada\n",
        "normalize =True \n",
        "#Especifique o tamanho matriz de confução deve ser plotada\n",
        "figsize = (5,5) # <<normal # figsize = (10,10) <<<Grande\n",
        "LOG = False\n",
        "class_names = ['0','1''2','3','4','5','6','7','8','9','10','11','12','13','14']\n",
        "pre = 4\n",
        "\n",
        "# KFOLD \n",
        "cv = 10\n",
        "\n",
        "clf_list = np.array([ \n",
        "            MultinomialNB(),        \n",
        "            MLPClassifier(max_iter=1000,solver='adam',learning_rate_init=5e-04),      \n",
        "            KNeighborsClassifier(),   \n",
        "            RandomForestClassifier(class_weight=class_weight),\n",
        "            svm.SVC(kernel='linear',class_weight=class_weight,probability=True,max_iter=3000,tol=1e-3),\n",
        "            svm.SVC(kernel='poly',class_weight=class_weight,probability=True,max_iter=3000,tol=1e-3),\n",
        "            svm.SVC(kernel='rbf',class_weight=class_weight,probability=True,max_iter=3000,tol=1e-3),\n",
        "           ])\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist_list = np.array([ \n",
        "                    #Bayes\n",
        "                    None, \n",
        "                    {\"hidden_layer_sizes\": list(np.arange(2,1001))},\n",
        "                    # KNN\n",
        "                    {\"n_neighbors\": [1,3,5,7,9,11]}, \n",
        "                    # Random Forest                   \n",
        "                    {  \"n_estimators\": [3000],\n",
        "                       \"max_depth\": [6, None],\n",
        "                       \"max_features\": sp_randint(1, 11),\n",
        "                       \"min_samples_split\": sp_randint(2, 11),\n",
        "                       \"min_samples_leaf\": sp_randint(1, 11),\n",
        "                       \"bootstrap\": [True, False],\n",
        "                       \"criterion\": [\"gini\", \"entropy\"]}\n",
        "                    ,\n",
        "                    # SVM Linear\n",
        "                    {'kernel': ['linear'], 'C': [2**i for i in range(-5,15)]},\n",
        "                    # SVM Polynomial    \n",
        "                    {'kernel': ['poly'], 'degree': [3, 5, 7 ,9], 'C': [2**i for i in range(-5,15)]},                    \n",
        "                    # SVM RBF    \n",
        "                    {'kernel': ['rbf'], 'gamma': [2**i for i in range(-15,3)], 'C': [2**i for i in range(-5,15)]},\n",
        "                    ])\n",
        "\n",
        "clf_name_list = np.array([\n",
        "                 'Bayes',              ## 0\n",
        "                 'MLP',                ## 1\n",
        "                 'Nearest_Neighbors',  ## 2\n",
        "                 'Random_Forest',      ## 3\n",
        "                 'SVM_Linear',         ## 4\n",
        "                 'SVM_Polynomial',     ## 5\n",
        "                 'SVM_RBF',            ## 6\n",
        "                ])\n",
        "scoring = {'accuracy': make_scorer(accuracy_score),\n",
        "           'precision_macro': 'precision_macro',\n",
        "           'recall_macro':'recall_macro',\n",
        "           'f1_macro':  'f1_macro',\n",
        "           'matthews_corrcoef':make_scorer(matthews_corrcoef)\n",
        "          }\n",
        "\n",
        "\n",
        "# Config classifiers\n",
        "# idx_clf = np.array(range(7))\n",
        "idx_clf = np.array([0,1,4,6])\n",
        "clf_name_list = clf_name_list[idx_clf]\n",
        "clf_list = clf_list[idx_clf]\n",
        "param_dist_list = param_dist_list[idx_clf]\n",
        "\n",
        "# number of interaction of 'random Search'\n",
        "n_iter_search_list = np.array([0,20,5,15,20,20,20])\n",
        "n_iter_search_list = n_iter_search_list[idx_clf]\n",
        "\n",
        "\n",
        "df_kfolds_scores = pd.DataFrame()\n",
        "df_mean_scores = pd.DataFrame()\n",
        "\n",
        "for model_name in model_name_list:\n",
        "  list_df = []\n",
        "  print('processing: '+model_name+' deep model')\n",
        "\n",
        "  X, y  = load_Ds('./data/'+model_name+'.npy')\n",
        "  X = normalizeX(X)           \n",
        "  X, y  = shuffle(X, y)\n",
        "\n",
        "  if(LOG):\n",
        "      print(\"\\nLoaded DS has:\",X.shape,\"intances\",y.shape,\"labels\")\n",
        "      print(\"Simplifly DS has:\",X.shape,\"intances\",y.shape,\"labels\")\n",
        "      num_classes = len(np.unique(y))\n",
        "      classes = [np.sum([1 for x in y if x==k]) for k in range(num_classes)]\n",
        "      print(\"Number of Classes:\",num_classes,\"with\",classes,\"elements respectively.\")\n",
        "\n",
        "\n",
        "  for idx, (clf ,clf_name,param_dist,n_iter_search) in enumerate(zip(clf_list,clf_name_list,param_dist_list,n_iter_search_list)): \n",
        "    if(param_dist != None): \n",
        "        random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=n_iter_search,n_jobs=-1,cv=2)\n",
        "        random_search.fit(X, y)\n",
        "        clf = random_search.best_estimator_\n",
        "#     else:\n",
        "#         clf.fit(X, y)\n",
        "\n",
        "    # Compute metrics with the best classifier configuration\n",
        "    scores = cross_validate(clf, X, y, cv=cv ,scoring=scoring)   \n",
        "\n",
        "    # Format log Dataframe \n",
        "    df = pd.DataFrame(scores) \n",
        "    ds_mean = df.mean()\n",
        "    ds_std = df.std() \n",
        "    df.insert(0, 'model', [model_name for i in range(cv)])\n",
        "    df.insert(1, 'classifier', [clf_name for i in range(cv)])  \n",
        "    df_kfolds_scores = df_kfolds_scores.append(df,ignore_index=True)\n",
        "    df.loc['mean'] = ds_mean    \n",
        "    df.loc['std'] = ds_std   \n",
        "    df = df.drop(columns=['model', 'classifier'])\n",
        "    df.insert(0, 'model', [model_name for i in range(cv+2)])\n",
        "    df.insert(1, 'classifier', [clf_name for i in range(cv+2)]) \n",
        "    list_df.append(df)\n",
        "\n",
        "  \n",
        "  # Display metrics summary\n",
        "  clear_output()    \n",
        "  df_total = pd.concat(list_df)\n",
        "  mean_std = df_total.drop(range(cv))\n",
        "  display(mean_std)\n",
        "\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  # This only needs to be done once per notebook.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  #Save log Dataframes into csv files\n",
        "  df_total.to_csv('./result_total_'+str(model_name)+'.csv', sep=',', mode='a')\n",
        "  mean_std.to_csv('./result_mean_std_'+str(model_name)+'.csv', sep=',', mode='a')\n",
        "  !ls\n",
        "\n",
        "  #Upload npy file to folder (by id)\n",
        "  file = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": out_folder_id}]})\n",
        "  file.SetContentFile('./result_total_'+str(model_name)+'.csv')\n",
        "  file.Upload() \n",
        "\n",
        "  #Upload npy file to folder (by id)\n",
        "  file = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": out_folder_id}]})\n",
        "  file.SetContentFile('./result_mean_std_'+str(model_name)+'.csv')\n",
        "  file.Upload() "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>classifier</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_f1_macro</th>\n",
              "      <th>test_matthews_corrcoef</th>\n",
              "      <th>test_precision_macro</th>\n",
              "      <th>test_recall_macro</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>train_f1_macro</th>\n",
              "      <th>train_matthews_corrcoef</th>\n",
              "      <th>train_precision_macro</th>\n",
              "      <th>train_recall_macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>Bayes</td>\n",
              "      <td>0.008232</td>\n",
              "      <td>0.006070</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>Bayes</td>\n",
              "      <td>0.000707</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>MLP</td>\n",
              "      <td>32.176362</td>\n",
              "      <td>0.070135</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>MLP</td>\n",
              "      <td>0.898158</td>\n",
              "      <td>0.002293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>SVM_Linear</td>\n",
              "      <td>2.737323</td>\n",
              "      <td>0.268332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>SVM_Linear</td>\n",
              "      <td>0.017306</td>\n",
              "      <td>0.003767</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>SVM_RBF</td>\n",
              "      <td>5.045208</td>\n",
              "      <td>0.337050</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>SVM_RBF</td>\n",
              "      <td>0.024629</td>\n",
              "      <td>0.001427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model  classifier   fit_time  score_time  test_accuracy  \\\n",
              "mean  DenseNet201       Bayes   0.008232    0.006070            1.0   \n",
              "std   DenseNet201       Bayes   0.000707    0.000293            0.0   \n",
              "mean  DenseNet201         MLP  32.176362    0.070135            1.0   \n",
              "std   DenseNet201         MLP   0.898158    0.002293            0.0   \n",
              "mean  DenseNet201  SVM_Linear   2.737323    0.268332            1.0   \n",
              "std   DenseNet201  SVM_Linear   0.017306    0.003767            0.0   \n",
              "mean  DenseNet201     SVM_RBF   5.045208    0.337050            1.0   \n",
              "std   DenseNet201     SVM_RBF   0.024629    0.001427            0.0   \n",
              "\n",
              "      test_f1_macro  test_matthews_corrcoef  test_precision_macro  \\\n",
              "mean            1.0                     1.0                   1.0   \n",
              "std             0.0                     0.0                   0.0   \n",
              "mean            1.0                     1.0                   1.0   \n",
              "std             0.0                     0.0                   0.0   \n",
              "mean            1.0                     1.0                   1.0   \n",
              "std             0.0                     0.0                   0.0   \n",
              "mean            1.0                     1.0                   1.0   \n",
              "std             0.0                     0.0                   0.0   \n",
              "\n",
              "      test_recall_macro  train_accuracy  train_f1_macro  \\\n",
              "mean                1.0             1.0             1.0   \n",
              "std                 0.0             0.0             0.0   \n",
              "mean                1.0             1.0             1.0   \n",
              "std                 0.0             0.0             0.0   \n",
              "mean                1.0             1.0             1.0   \n",
              "std                 0.0             0.0             0.0   \n",
              "mean                1.0             1.0             1.0   \n",
              "std                 0.0             0.0             0.0   \n",
              "\n",
              "      train_matthews_corrcoef  train_precision_macro  train_recall_macro  \n",
              "mean                      1.0                    1.0                 1.0  \n",
              "std                       0.0                    0.0                 0.0  \n",
              "mean                      1.0                    1.0                 1.0  \n",
              "std                       0.0                    0.0                 0.0  \n",
              "mean                      1.0                    1.0                 1.0  \n",
              "std                       0.0                    0.0                 0.0  \n",
              "mean                      1.0                    1.0                 1.0  \n",
              "std                       0.0                    0.0                 0.0  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t\t       result_mean_std_Xception.csv\r\n",
            "datalab\t\t\t\t       result_total_DenseNet121.csv\r\n",
            "out\t\t\t\t       result_total_DenseNet169.csv\r\n",
            "result_mean_std_DenseNet121.csv        result_total_DenseNet201.csv\r\n",
            "result_mean_std_DenseNet169.csv        result_total_InceptionResNetV2.csv\r\n",
            "result_mean_std_DenseNet201.csv        result_total_InceptionV3.csv\r\n",
            "result_mean_std_InceptionResNetV2.csv  result_total_MobileNet.csv\r\n",
            "result_mean_std_InceptionV3.csv        result_total_NASNetLarge.csv\r\n",
            "result_mean_std_MobileNet.csv\t       result_total_NASNetMobile.csv\r\n",
            "result_mean_std_NASNetLarge.csv        result_total_ResNet50.csv\r\n",
            "result_mean_std_NASNetMobile.csv       result_total_VGG16.csv\r\n",
            "result_mean_std_ResNet50.csv\t       result_total_VGG19.csv\r\n",
            "result_mean_std_VGG16.csv\t       result_total_Xception.csv\r\n",
            "result_mean_std_VGG19.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xOmZckr1z806",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ['accuracy', \n",
        "#  'adjusted_mutual_info_score', \n",
        "#  'adjusted_rand_score',\n",
        "#  'average_precision',\n",
        "#  'completeness_score',\n",
        "#  'explained_variance', \n",
        "#  'f1',\n",
        "#  'f1_macro', \n",
        "#  'f1_micro', \n",
        "#  'f1_samples',\n",
        "#  'f1_weighted',\n",
        "#  'fowlkes_mallows_score',\n",
        "#  'homogeneity_score',\n",
        "#  'mutual_info_score',\n",
        "#  'neg_log_loss',\n",
        "#  'neg_mean_absolute_error',\n",
        "#  'neg_mean_squared_error',\n",
        "#  'neg_mean_squared_log_error',\n",
        "#  'neg_median_absolute_error',\n",
        "#  'normalized_mutual_info_score',\n",
        "#  'precision', \n",
        "#  'precision_macro', \n",
        "#  'precision_micro',\n",
        "#  'precision_samples', \n",
        "#  'precision_weighted', \n",
        "#  'r2', \n",
        "#  'recall', \n",
        "#  'recall_macro',\n",
        "#  'recall_micro', \n",
        "#  'recall_samples', \n",
        "#  'recall_weighted', \n",
        "#  'roc_auc', \n",
        "#  'v_measure_score']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vWmnywdZQsUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e262e918-ae78-4ae3-fe27-f4d7a8d8a49d"
      },
      "cell_type": "code",
      "source": [
        "print('Done')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  datalab  result_kfold_Xception.csv  result_mean_std_Xception.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p48IiVazD2pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}